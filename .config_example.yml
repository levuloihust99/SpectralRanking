# data pipeline
data_config:
  main_data_path: data/v2/compare/byte/train
  negpool_data_path: data/v2/negpool/byte/train
  regulate_factors:
    sliding: 1
    nonconciseness: 1
    noncoherence: 1
    noncoverage: 1
    model_compare: 1
    negpool: 1
  buffer_size: 10
  contrastive_size: 10
  batch_size: 60
  prefetch_factor: 100
  sep_token: <extra_id_0>
  tokenizer_path: VietAI/vit5-base
  max_input_len: 1500
  pipelines:
    sliding: {}
    nonconciseness: {}
    noncoherence: {}
    noncoverage: {}
    model_compare: {}
    negpool: {}

# eval data pipeline
eval_data_config:
  main_data_path: data/v2/compare/byte/eval
  negpool_data_path: data/v2/negpool/byte/eval
  buffer_size: 10
  batch_size: 16
  max_dataloader_len: 5000
  pipelines:
    sliding:
    nonconciseness:
    noncoherence:
    noncoverage:
    model_compare:
    negpool:

# model
type_model: t5
path_to_model: VietAI/vit5-base

# training
output_dir: assets/outputs/spectral-ranking-v2
do_train: true
do_eval: true
score_scale: 1.0
learning_rate: 2e-5
num_train_steps: 20000
warmup_ratio: 0.0
warmup_steps: 0
weight_decay: 0.0
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
adam_eps: 1e-8
save_steps: 500
eval_steps: 500
save_total_limit: 5
max_grad_norm: 1.0
metric_for_best_model: eval/acc
greater_is_better: true
resume_from_checkpoint:
seed: 12345

# data
max_input_len: 1500

# log config
log_level: info
report_to:
  - wandb
wandb_api_key:
wandb_project:
logging_dir: assets/logs/spectral-ranking-v2
logging_steps: 10
